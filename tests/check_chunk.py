import json
from datetime import datetime  
import re
from typing import Dict, List, Tuple
import pandas as pd
import matplotlib.pyplot as plt
from collections import Counter
import os

def check_chunks_quality(file_path: str = r"C:\Users\nguye\OneDrive\M√°y t√≠nh\CHATBOT\data\chunks\chunks_20250204_122842.json"):
    class ChunkQualityChecker:
        def __init__(self):
            self.min_content_words = 20
            self.max_content_words = 200
            self.required_metadata_fields = [
                "file_name", "processed_date", "ma_thu_tuc",
                "ten_thu_tuc", "cap_thuc_hien", "linh_vuc",
                "section_name", "created_at"
            ]
            self.results = []
            
        def validate_datetime(self, date_str: str) -> bool:
            try:
                datetime.fromisoformat(date_str)
                return True
            except ValueError:
                return False
        
        def validate_ma_thu_tuc(self, ma_thu_tuc: str) -> bool:
            pattern = r'^\d+\.\d{6}\.\d{3}\.\d{2}\.\d{2}\.[A-Z0-9]+$'
            return bool(re.match(pattern, ma_thu_tuc))
        
        def check_content_quality(self, content: str) -> Tuple[bool, List[str]]:
            issues = []
            word_count = len(content.split())
            
            if word_count < self.min_content_words:
                issues.append(f"N·ªôi dung qu√° ng·∫Øn ({word_count} t·ª´ < {self.min_content_words})")
            if word_count > self.max_content_words:
                issues.append(f"N·ªôi dung qu√° d√†i ({word_count} t·ª´ > {self.max_content_words})")
                
            if not content.strip().endswith(('.', '?', '!')):
                issues.append("N·ªôi dung kh√¥ng k·∫øt th√∫c b·∫±ng d·∫•u c√¢u ph√π h·ª£p")
                
            if len(set(content.split())) / len(content.split()) < 0.3:
                issues.append("N·ªôi dung c√≥ nhi·ªÅu t·ª´ l·∫∑p l·∫°i")
                
            return len(issues) == 0, issues
        
        def check_chunk(self, chunk: Dict) -> Dict:
            result = {
                "chunk_id": len(self.results) + 1,
                "metadata_issues": [],
                "content_issues": [],
                "status": "PASS"
            }
            
            metadata = chunk.get("metadata", {})
            for field in self.required_metadata_fields:
                if field not in metadata:
                    result["metadata_issues"].append(f"Thi·∫øu tr∆∞·ªùng metadata: {field}")
                    
            if "processed_date" in metadata and not self.validate_datetime(metadata["processed_date"]):
                result["metadata_issues"].append("ƒê·ªãnh d·∫°ng processed_date kh√¥ng h·ª£p l·ªá")
                
            if "created_at" in metadata and not self.validate_datetime(metadata["created_at"]):
                result["metadata_issues"].append("ƒê·ªãnh d·∫°ng created_at kh√¥ng h·ª£p l·ªá")
                
            if "ma_thu_tuc" in metadata and not self.validate_ma_thu_tuc(metadata["ma_thu_tuc"]):
                result["metadata_issues"].append("Format m√£ th·ªß t·ª•c kh√¥ng h·ª£p l·ªá")
                
            content = chunk.get("content", "")
            content_valid, content_issues = self.check_content_quality(content)
            result["content_issues"].extend(content_issues)
            
            if result["metadata_issues"] or result["content_issues"]:
                result["status"] = "FAIL"
                
            self.results.append(result)
            return result
        
        def analyze_chunks(self, chunks: List[Dict]) -> None:
            for chunk in chunks:
                self.check_chunk(chunk)
                
        def generate_report(self) -> None:
            df = pd.DataFrame(self.results)
            
            total_chunks = len(self.results)
            passed_chunks = len([r for r in self.results if r["status"] == "PASS"])
            failed_chunks = total_chunks - passed_chunks
            
            plt.figure(figsize=(15, 10))
            
            plt.subplot(2, 2, 1)
            plt.pie([passed_chunks, failed_chunks], 
                    labels=['PASS', 'FAIL'],
                    autopct='%1.1f%%',
                    colors=['green', 'red'])
            plt.title('T·ª∑ l·ªá Chunks Pass/Fail')
            
            all_issues = []
            for r in self.results:
                all_issues.extend(r["metadata_issues"])
                all_issues.extend(r["content_issues"])
            
            issue_counts = Counter(all_issues)
            if issue_counts:
                plt.subplot(2, 2, 2)
                issues, counts = zip(*issue_counts.most_common(5))
                plt.barh(issues, counts)
                plt.title('Top 5 v·∫•n ƒë·ªÅ ph·ªï bi·∫øn nh·∫•t')
            
            plt.tight_layout()

            # üîπ T·∫°o th∆∞ m·ª•c "figure" n·∫øu ch∆∞a t·ªìn t·∫°i
            base_dir = r"C:\Users\nguye\OneDrive\M√°y t√≠nh\CHATBOT\data"
            figure_dir = os.path.join(base_dir, "figures")
            os.makedirs(figure_dir, exist_ok=True)

            # üîπ L∆∞u k·∫øt qu·∫£ v√†o th∆∞ m·ª•c "figure"
            current_time = datetime.now().strftime('%Y%m%d_%H%M%S')
            figure_path = os.path.join(figure_dir, f'chunk_quality_report_{current_time}.png')

            plt.savefig(figure_path, dpi=300, bbox_inches='tight')
            plt.show()
            
            print("\n=== B√ÅO C√ÅO KI·ªÇM TRA CH·∫§T L∆Ø·ª¢NG CHUNKS ===")
            print(f"T·ªïng s·ªë chunks: {total_chunks}")
            print(f"S·ªë chunks ƒë·∫°t y√™u c·∫ßu: {passed_chunks} ({passed_chunks/total_chunks*100:.1f}%)")
            print(f"S·ªë chunks kh√¥ng ƒë·∫°t: {failed_chunks} ({failed_chunks/total_chunks*100:.1f}%)")
            print(f"\nüìÅ Bi·ªÉu ƒë·ªì ƒë√£ ƒë∆∞·ª£c l∆∞u t·∫°i: {figure_path}")
            
            if issue_counts:
                print("\nC√°c v·∫•n ƒë·ªÅ ph·ªï bi·∫øn nh·∫•t:")
                for issue, count in issue_counts.most_common(5):
                    print(f"- {issue}: {count} l·∫ßn")

            # üîπ L∆∞u b√°o c√°o d·∫°ng text
            report_path = os.path.join(figure_dir, f'chunk_quality_report_{current_time}.txt')
            with open(report_path, 'w', encoding='utf-8') as f:
                f.write("=== B√ÅO C√ÅO KI·ªÇM TRA CH·∫§T L∆Ø·ª¢NG CHUNKS ===\n")
                f.write(f"T·ªïng s·ªë chunks: {total_chunks}\n")
                f.write(f"S·ªë chunks ƒë·∫°t y√™u c·∫ßu: {passed_chunks} ({passed_chunks/total_chunks*100:.1f}%)\n")
                f.write(f"S·ªë chunks kh√¥ng ƒë·∫°t: {failed_chunks} ({failed_chunks/total_chunks*100:.1f}%)\n")
                if issue_counts:
                    f.write("\nC√°c v·∫•n ƒë·ªÅ ph·ªï bi·∫øn nh·∫•t:\n")
                    for issue, count in issue_counts.most_common(5):
                        f.write(f"- {issue}: {count} l·∫ßn\n")

    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            chunks = json.load(f)
    except Exception as e:
        print(f"L·ªói khi ƒë·ªçc file: {str(e)}")
        return
    
    checker = ChunkQualityChecker()
    checker.analyze_chunks(chunks)
    checker.generate_report()
    
    return checker.results

# Ch·∫°y ki·ªÉm tra
if __name__ == "__main__":
    results = check_chunks_quality()
