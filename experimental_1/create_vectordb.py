import os
import json
import logging
from dotenv import load_dotenv
import together
from pymilvus import connections, FieldSchema, CollectionSchema, DataType, Collection, utility

# C·∫•u h√¨nh logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Load bi·∫øn m√¥i tr∆∞·ªùng t·ª´ .env
load_dotenv()

class VectorDBCreator:
    def __init__(self):
        # API Key cho Together AI (Embedding Model)
        self.api_key = os.getenv("TOGETHER_API_KEY_1")
        self.together_client = together.Together(api_key=self.api_key)

        # K·∫øt n·ªëi Zilliz Cloud
        self.uri = f"https://{os.getenv('ZILLIZ_HOST')}"
        self.token = os.getenv("ZILLIZ_API_KEY")
        self.collection_name = "tthc_vectors_1"
        self.dim = 768  # K√≠ch th∆∞·ªõc vector embedding

        # ƒê∆∞·ªùng d·∫´n th∆∞ m·ª•c ch·ª©a chunks
        self.chunks_dir = os.path.join(os.getcwd(), "experimental_2", "data", "chunks")

        self.connect_zilliz()
        self.create_collection()

    def connect_zilliz(self):
        """K·∫øt n·ªëi ƒë·∫øn Zilliz Cloud"""
        connections.connect(uri=self.uri, token=self.token)
        logger.info("‚úÖ K·∫øt n·ªëi Zilliz Cloud th√†nh c√¥ng!")

    def create_collection(self):
        """T·∫°o collection trong Zilliz n·∫øu ch∆∞a t·ªìn t·∫°i"""
        if utility.has_collection(self.collection_name):
            logger.info(f"‚úÖ Collection '{self.collection_name}' ƒë√£ t·ªìn t·∫°i.")
            return

        fields = [
            FieldSchema(name="id", dtype=DataType.INT64, is_primary=True, auto_id=True),
            FieldSchema(name="embedding", dtype=DataType.FLOAT_VECTOR, dim=self.dim),
            FieldSchema(name="content", dtype=DataType.VARCHAR, max_length=65535),
            FieldSchema(name="intent", dtype=DataType.VARCHAR, max_length=100),
            FieldSchema(name="section_name", dtype=DataType.VARCHAR, max_length=255)
        ]

        schema = CollectionSchema(fields)
        collection = Collection(self.collection_name, schema)
        collection.create_index(field_name="embedding", index_params={"metric_type": "L2", "index_type": "HNSW"})

        logger.info(f"‚úÖ T·∫°o collection '{self.collection_name}' th√†nh c√¥ng!")

    def get_embedding(self, text: str):
        """T·∫°o embedding t·ª´ vƒÉn b·∫£n s·ª≠ d·ª•ng Together AI"""
        response = self.together_client.embeddings.create(
            input=[text],
            model="togethercomputer/m2-bert-80M-32k-retrieval"
        )
        return response.data[0].embedding

    def insert_chunks(self):
        """Qu√©t t·∫•t c·∫£ file chunks trong th∆∞ m·ª•c v√† ch√®n v√†o Zilliz"""
        collection = Collection(self.collection_name)
        collection.load()

        if not os.path.exists(self.chunks_dir):
            logger.error(f"‚ùå Th∆∞ m·ª•c {self.chunks_dir} kh√¥ng t·ªìn t·∫°i!")
            return

        files = [f for f in os.listdir(self.chunks_dir) if f.endswith(".json")]
        if not files:
            logger.error(f"‚ùå Kh√¥ng t√¨m th·∫•y file chunks trong {self.chunks_dir}!")
            return

        logger.info(f"üìÇ T√¨m th·∫•y {len(files)} file chunks, b·∫Øt ƒë·∫ßu insert...")

        for file_name in files:
            file_path = os.path.join(self.chunks_dir, file_name)
            logger.info(f"üì• ƒêang x·ª≠ l√Ω file: {file_path}")

            with open(file_path, 'r', encoding='utf-8') as f:
                chunks = json.load(f)

            entities = []
            for chunk in chunks:
                content = chunk["content"]
                metadata = chunk["metadata"]
                embedding = self.get_embedding(content)

                entity = {
                    "embedding": embedding,
                    "content": content,
                    "intent": metadata.get("intent", ""),
                    "section_name": metadata.get("section_name", "")
                }
                entities.append(entity)

            collection.insert(entities)
            logger.info(f"‚úÖ ƒê√£ insert {len(entities)} chunks t·ª´ file {file_name} v√†o Zilliz!")

        collection.flush()
        logger.info("‚úÖ Ho√†n th√†nh insert t·∫•t c·∫£ file v√†o Zilliz!")

def main():
    creator = VectorDBCreator()
    creator.insert_chunks()

if __name__ == "__main__":
    main()
