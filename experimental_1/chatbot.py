import os
import logging
from dotenv import load_dotenv
from langchain_community.vectorstores import Zilliz
from langchain_together import ChatTogether, TogetherEmbeddings
from langchain.prompts import PromptTemplate
from langchain.chains import RetrievalQA

# C·∫•u h√¨nh logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Load API Key t·ª´ .env
load_dotenv()

class RAGChatbot:
    def __init__(self):
        self.api_key = os.getenv("TOGETHER_API_KEY_1")
        self.llm_api_key = os.getenv("TOGETHER_API_KEY_2")

        # Kh·ªüi t·∫°o model embedding
        self.embeddings = TogetherEmbeddings(
            model="togethercomputer/m2-bert-80M-32k-retrieval",
            together_api_key=self.api_key
        )

        # Kh·ªüi t·∫°o LLM (Llama 3)
        self.llm = ChatTogether(
            model="meta-llama/Llama-3.3-70B-Instruct-Turbo",
            together_api_key=self.llm_api_key
        )

        # K·∫øt n·ªëi ƒë·∫øn Zilliz
        self.vector_store = Zilliz(
            embedding_function=self.embeddings,
            collection_name="tthc_vectors_1",
            connection_args={"uri": f"https://{os.getenv('ZILLIZ_HOST')}", "token": os.getenv("ZILLIZ_API_KEY")},
            vector_field="embedding",
            text_field="content"
        )

        # T·∫°o template cho prompt
        self.create_prompt_template()
        self.setup_retrieval_qa()

    def create_prompt_template(self):
        """T·∫°o template cho LLM"""
        self.prompt = PromptTemplate(
            template="""D·ª±a tr√™n th√¥ng tin d∆∞·ªõi ƒë√¢y, h√£y tr·∫£ l·ªùi c√¢u h·ªèi m·ªôt c√°ch ng·∫Øn g·ªçn v√† ch√≠nh x√°c:\n\n{context}\n\nC√¢u h·ªèi: {question}\n\nTr·∫£ l·ªùi:""",
            input_variables=["context", "question"]
        )

    def setup_retrieval_qa(self):
        """Thi·∫øt l·∫≠p truy v·∫•n t√¨m ki·∫øm"""
        self.qa_chain = RetrievalQA.from_chain_type(
            llm=self.llm,
            retriever=self.vector_store.as_retriever(search_kwargs={"k": 5}),
            return_source_documents=True,
            chain_type_kwargs={"prompt": self.prompt}
        )

    def analyze_question(self, question):  
        """
        Ph√¢n t√≠ch c√¢u h·ªèi ƒë·ªÉ tr√≠ch xu·∫•t `intent` v√† `section_name` c·∫ßn t√¨m ki·∫øm.
        """
        question = question.lower()
        intent_mapping = {
            "tr√¨nh t·ª±": ["b∆∞·ªõc th·ª±c hi·ªán", "quy tr√¨nh", "tr√¨nh t·ª±"],
            "c√°ch th·ª©c": ["l√†m nh∆∞ th·∫ø n√†o", "n·ªôp h·ªì s∆°", "th·ª±c hi·ªán nh∆∞ th·∫ø n√†o"],
            "h·ªì s∆°": ["gi·∫•y t·ªù", "h·ªì s∆° c·∫ßn c√≥", "c·∫ßn chu·∫©n b·ªã nh·ªØng g√¨"],
            "th·ªùi h·∫°n": ["m·∫•t bao l√¢u", "th·ªùi gian x·ª≠ l√Ω"],
            "ph√≠": ["chi ph√≠", "ph√≠ bao nhi√™u"],
            "ph√°p l√Ω": ["quy ƒë·ªãnh ph√°p lu·∫≠t", "cƒÉn c·ª© ph√°p l√Ω"],
            "ƒëi·ªÅu ki·ªán": ["ƒëi·ªÅu ki·ªán c·∫ßn c√≥", "ai ƒë∆∞·ª£c ph√©p"]
        }

        detected_intent = "kh√°c"
        detected_section = "Th√¥ng tin chung"

        for intent, keywords in intent_mapping.items():
            for keyword in keywords:
                if keyword in question:
                    detected_intent = intent
                    detected_section = keyword
                    break

        return {"intent": detected_intent, "section_name": detected_section}

    def answer_question(self, question):
        """T√¨m ki·∫øm d·ªØ li·ªáu d·ª±a tr√™n intent & section_name t·ª´ ph√¢n t√≠ch c√¢u h·ªèi."""
        analysis = self.analyze_question(question)
        intent = analysis["intent"]
        section_name = analysis["section_name"]

        print(f"\nüîç **PH√ÇN T√çCH C√ÇU H·ªéI:**")
        print(f"üõ† Intent: {intent}")
        print(f"üìå Section Name: {section_name}")

        # T·∫°o b·ªô l·ªçc d·ª±a v√†o intent & section_name
        filter_dict = {
            "intent": intent,
            "section_name": section_name
        }

        # T√¨m ki·∫øm d·ªØ li·ªáu theo b·ªô l·ªçc ƒë√£ ph√¢n t√≠ch
        docs = self.vector_store.similarity_search(question, k=10, filter=filter_dict)

        # Hi·ªÉn th·ªã k·∫øt qu·∫£ t√¨m ƒë∆∞·ª£c t·ª´ Zilliz
        if docs:
            print("\nüîç **K·∫æT QU·∫¢ EMBEDDING T√åM ƒê∆Ø·ª¢C:**")
            for idx, doc in enumerate(docs, 1):
                print(f"\n=== üìù **T√ÄI LI·ªÜU {idx}** ===")
                print(f"üìú **N·ªôi dung (content):**\n{doc.page_content}")  # üî• In to√†n b·ªô n·ªôi dung t·ª´ Zilliz
                print(f"üìå **Metadata:** {doc.metadata}")
                print(f"üî¢ **Embedding:** {doc.metadata.get('embedding', 'Kh√¥ng c√≥')[:3]}...")  
                print("=" * 50)

        else:
            print("\n‚ùå **Kh√¥ng t√¨m th·∫•y t√†i li·ªáu li√™n quan!**")

        # N·∫øu kh√¥ng t√¨m th·∫•y d·ªØ li·ªáu, tr·∫£ v·ªÅ th√¥ng b√°o
        if not docs:
            return "‚ùå Kh√¥ng t√¨m th·∫•y th√¥ng tin ph√π h·ª£p."

        # G·ª≠i d·ªØ li·ªáu ƒë·∫øn LLM ƒë·ªÉ t·∫°o c√¢u tr·∫£ l·ªùi
        response = self.qa_chain.invoke({"query": question, "input_documents": docs})
        return response["result"]

    def chat(self):
        """Kh·ªüi ƒë·ªông chatbot"""
        print("ü§ñ Chatbot s·∫µn s√†ng! Nh·∫≠p c√¢u h·ªèi c·ªßa b·∫°n:")
        while True:
            question = input("üë§ B·∫°n: ").strip()
            if question.lower() == "quit":
                break
            print(f"ü§ñ Bot: {self.answer_question(question)}")

if __name__ == "__main__":
    RAGChatbot().chat()
